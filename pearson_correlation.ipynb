{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pearson_correlation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPcksCs3Q6twbUaW5GEthbi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pesfahanian/pearson_correlation/blob/main/pearson_correlation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZAHUX8Spjj0"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.applications.densenet import DenseNet121\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.datasets.mnist import load_data\n",
        "from tensorflow.keras.applications.densenet import preprocess_input"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovOd9CCx8xln"
      },
      "source": [
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "batch_size = 128\n",
        "epochs = 15"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jkmtBtS59Zr",
        "outputId": "bf69b69a-6ed8-4978-db80-8a4555a15fcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "size = 10\n",
        "indices = random.sample(range(0, 59999), 10)\n",
        "print(indices)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[53780, 33666, 34091, 18688, 37985, 46093, 15813, 7925, 30879, 58840]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVCfIhmU86X_",
        "outputId": "571e256b-56d5-480f-e8b8-2d3be1530a06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohVIXO196ZL_"
      },
      "source": [
        "x_sample = []\n",
        "y_sample = []\n",
        "for i in indices:\n",
        "    x_sample.append(x_train[i])\n",
        "    y_sample.append(y_train[i])\n",
        "x_sample = np.array(x_sample)\n",
        "y_sample = np.array(y_sample)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g2LlJ_T_LYv"
      },
      "source": [
        "x_sample = x_sample.astype(\"float32\") / 255\n",
        "x_sample = np.expand_dims(x_sample, -1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvMarejH-7yZ",
        "outputId": "335838a0-9e4b-4040-ed0b-1172edb2ef16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x_sample.shape)\n",
        "print(y_sample.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 28, 28, 1)\n",
            "(10,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-Xxhs9x6wDX",
        "outputId": "bec0f627-93a1-41bb-816f-7314ffe6fc8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(y_sample)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 2 1 9 2 1 1 0 7 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHPIHBLisPHx",
        "outputId": "397066e4-603b-462b-bb3c-168c4de93cba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.imshow(x_sample[0])\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAL10lEQVR4nO3dX4hc9RnG8ecxjUmNCom22xhD/UOsitBY1tiiFItV1EKjvRBTkBTElWJAwYuKvah3lVIVL1phramxWKWg1lCCNU3VVCjiKmn+mNaoRMx2zWpDm/gvxuzbiz2RVXfOTuacmTP6fj8wzMx5z8x5OfHxnDm/2fk5IgTg8++IphsA0BuEHUiCsANJEHYgCcIOJPGFXm7sSM+JuZrXy00Cqbyvd/RB7Pd0tUpht32JpLskzZL0m4i4rWz9uZqnc31hlU0CKPFsbGhZ6/g03vYsSb+SdKmkMyWtsH1mp+8HoLuqfGZfJunliHg1Ij6Q9JCk5fW0BaBuVcK+SNLrU57vKpZ9jO0h2yO2Rw5of4XNAaii61fjI2I4IgYjYnC25nR7cwBaqBL2UUmLpzw/sVgGoA9VCftzkpbYPtn2kZKukrS2nrYA1K3jobeI+ND2Kkl/1uTQ2+qI2FZbZwBqVWmcPSLWSVpXUy8AuoivywJJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BEpVlc0f/eu3xZaX3jr4dL66tGzy2t7zhn/2H3hGZUCrvtnZL2SToo6cOIGKyjKQD1q+PI/p2IeKuG9wHQRXxmB5KoGvaQ9ITt520PTbeC7SHbI7ZHDojPd0BTqp7Gnx8Ro7a/LGm97X9GxMapK0TEsKRhSTrWC6Li9gB0qNKRPSJGi/txSY9KKr/0C6AxHYfd9jzbxxx6LOliSVvragxAvaqcxg9IetT2off5fUQ8XktXqM3bC2eV1g/EwdL6CXP+W1p/9bhFpfWD/9lTWkfvdBz2iHhV0tdr7AVAFzH0BiRB2IEkCDuQBGEHkiDsQBKO6N2X2o71gjjXF/Zse5jZn0afL61PaKK0fvrjPy6tn3bNyGH3hM49Gxu0N/Z4uhpHdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1Igp+SRiXHD+xtugW0iSM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOHtyR2jaP33+2Br4fOBfEkiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJw9uQmVzxsw0+/G47NjxiO77dW2x21vnbJsge31tncU9/O72yaAqto5jb9P0iWfWHazpA0RsUTShuI5gD42Y9gjYqOkPZ9YvFzSmuLxGkmX19wXgJp1+pl9ICLGisdvSBpotaLtIUlDkjRXR3W4OQBVVb4aH5MzQ7a8yhMRwxExGBGDszWn6uYAdKjTsO+2vVCSivvx+loC0A2dhn2tpJXF45WSHqunHQDd0s7Q24OS/i7pa7Z32b5G0m2SLrK9Q9J3i+cA+tiMF+giYkWL0oU19wKgi/i6LJAEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSfBT0skNvX5BaX148VOl9WtPfaa0/sfTvtWydvClV0pfi3pxZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnT+6pLaeX1icW/7W0vvLY10rrP7/pey1rp13HOHsvcWQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ0dXnXLq7qZbQKGd+dlX2x63vXXKslttj9reVNwu626bAKpq5zT+PkmXTLP8zohYWtzW1dsWgLrNGPaI2ChpTw96AdBFVS7QrbK9uTjNn99qJdtDtkdsjxzQ/gqbA1BFp2G/W9KpkpZKGpN0e6sVI2I4IgYjYnC25nS4OQBVdRT2iNgdEQcjYkLSPZKW1dsWgLp1FHbbC6c8vULS1lbrAugPM46z235Q0gWSjre9S9LPJF1ge6mkkLRT0nVd7BFddNo975evUHFQdd0ZD7esfV/nVHtzHJYZwx4RK6ZZfG8XegHQRXxdFkiCsANJEHYgCcIOJEHYgST4E9fkZv3vvdL6ERwPPjf4lwSSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnz25svLR8w7/PK63fecLf6uwGXcSRHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJw9uYN795bWR8aXlL/BCTU2g67iyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IIkZw257se0nbb9oe5vtG4rlC2yvt72juJ/f/XYBdKqdI/uHkm6KiDMlfVPS9bbPlHSzpA0RsUTShuI5gD41Y9gjYiwiXige75O0XdIiScslrSlWWyPp8m41CaC6w/puvO2TJJ0t6VlJAxExVpTekDTQ4jVDkoYkaa6O6rRPABW1fYHO9tGSHpZ0Y0R87K8nIiIkxXSvi4jhiBiMiMHZmlOpWQCdayvstmdrMugPRMQjxeLdthcW9YWSyn+mFECjZjyNt21J90raHhF3TCmtlbRS0m3F/WNd6RCN2vvO3NI6Uzp/drTzmf08SVdL2mJ7U7HsFk2G/A+2r5H0mqQru9MigDrMGPaIeEaSW5QvrLcdAN3CORiQBGEHkiDsQBKEHUiCsANJ8FPSKPWV35aPs0+cN9GjTlAVR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1Igr9nR6kvPr2ttH7W09eW1n9wxqbSOnqHIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJNHO/OyLJd0vaUBSSBqOiLts3yrpWklvFqveEhHrutUomjHx7rul9VN+WD6Ozih7/2jnSzUfSropIl6wfYyk522vL2p3RsQvu9cegLq0Mz/7mKSx4vE+29slLep2YwDqdVif2W2fJOlsSc8Wi1bZ3mx7te35LV4zZHvE9sgB7a/ULIDOtR1220dLeljSjRGxV9Ldkk6VtFSTR/7bp3tdRAxHxGBEDM7WnBpaBtCJtsJue7Ymg/5ARDwiSRGxOyIORsSEpHskLetemwCqmjHsti3pXknbI+KOKcsXTlntCklb628PQF3auRp/nqSrJW2xfWgk5RZJK2wv1eRw3E5J13WlQwC1aOdq/DOSPE2JMXXgM4Rv0AFJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JwRPRuY/abkl6bsuh4SW/1rIHD06+99WtfEr11qs7evhoRX5qu0NOwf2rj9khEDDbWQIl+7a1f+5LorVO96o3TeCAJwg4k0XTYhxvefpl+7a1f+5LorVM96a3Rz+wAeqfpIzuAHiHsQBKNhN32Jbb/Zftl2zc30UMrtnfa3mJ7k+2RhntZbXvc9tYpyxbYXm97R3E/7Rx7DfV2q+3RYt9tsn1ZQ70ttv2k7Rdtb7N9Q7G80X1X0ldP9lvPP7PbniXpJUkXSdol6TlJKyLixZ420oLtnZIGI6LxL2DY/raktyXdHxFnFct+IWlPRNxW/I9yfkT8pE96u1XS201P413MVrRw6jTjki6X9CM1uO9K+rpSPdhvTRzZl0l6OSJejYgPJD0kaXkDffS9iNgoac8nFi+XtKZ4vEaT/7H0XIve+kJEjEXEC8XjfZIOTTPe6L4r6asnmgj7IkmvT3m+S/0133tIesL287aHmm5mGgMRMVY8fkPSQJPNTGPGabx76RPTjPfNvutk+vOquED3aedHxDckXSrp+uJ0tS/F5Gewfho7bWsa716ZZprxjzS57zqd/ryqJsI+KmnxlOcnFsv6QkSMFvfjkh5V/01FvfvQDLrF/XjD/Xykn6bxnm6acfXBvmty+vMmwv6cpCW2T7Z9pKSrJK1toI9PsT2vuHAi2/MkXaz+m4p6raSVxeOVkh5rsJeP6ZdpvFtNM66G913j059HRM9vki7T5BX5VyT9tIkeWvR1iqR/FLdtTfcm6UFNntYd0OS1jWskHSdpg6Qdkv4iaUEf9fY7SVskbdZksBY21Nv5mjxF3yxpU3G7rOl9V9JXT/YbX5cFkuACHZAEYQeSIOxAEoQdSIKwA0kQdiAJwg4k8X/djZce36/6rQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9bIWce68wWC",
        "outputId": "171da042-96a9-4347-9a48-610f7324928d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbYPYT3f9UWH"
      },
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjZzD3Lm9aNI",
        "outputId": "2f87298b-9af7-4e44-de9f-448f427e9da3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                16010     \n",
            "=================================================================\n",
            "Total params: 34,826\n",
            "Trainable params: 34,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoJ9bmPL9tqf"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS7ACvVR9lb7",
        "outputId": "20cb01a4-b747-4517-8dc4-73d1ce6e987e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.3638 - accuracy: 0.8865 - val_loss: 0.0809 - val_accuracy: 0.9758\n",
            "Epoch 2/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1123 - accuracy: 0.9655 - val_loss: 0.0544 - val_accuracy: 0.9842\n",
            "Epoch 3/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0825 - accuracy: 0.9738 - val_loss: 0.0466 - val_accuracy: 0.9872\n",
            "Epoch 4/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0690 - accuracy: 0.9784 - val_loss: 0.0429 - val_accuracy: 0.9895\n",
            "Epoch 5/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0623 - accuracy: 0.9807 - val_loss: 0.0412 - val_accuracy: 0.9897\n",
            "Epoch 6/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0554 - accuracy: 0.9823 - val_loss: 0.0367 - val_accuracy: 0.9898\n",
            "Epoch 7/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0519 - accuracy: 0.9834 - val_loss: 0.0355 - val_accuracy: 0.9912\n",
            "Epoch 8/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0477 - accuracy: 0.9848 - val_loss: 0.0308 - val_accuracy: 0.9922\n",
            "Epoch 9/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0447 - accuracy: 0.9856 - val_loss: 0.0320 - val_accuracy: 0.9918\n",
            "Epoch 10/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0404 - accuracy: 0.9876 - val_loss: 0.0307 - val_accuracy: 0.9917\n",
            "Epoch 11/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0396 - accuracy: 0.9869 - val_loss: 0.0324 - val_accuracy: 0.9927\n",
            "Epoch 12/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0374 - accuracy: 0.9875 - val_loss: 0.0290 - val_accuracy: 0.9927\n",
            "Epoch 13/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0348 - accuracy: 0.9885 - val_loss: 0.0298 - val_accuracy: 0.9917\n",
            "Epoch 14/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0346 - accuracy: 0.9887 - val_loss: 0.0315 - val_accuracy: 0.9913\n",
            "Epoch 15/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0317 - accuracy: 0.9896 - val_loss: 0.0309 - val_accuracy: 0.9925\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0a2021d748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS9QnV9Z90bd",
        "outputId": "bca22627-df51-458e-838d-3061a7aa00f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.02440529130399227\n",
            "Test accuracy: 0.9915000200271606\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XO1piGA-AF5"
      },
      "source": [
        "feature_extractor = Model(inputs=model.input, outputs=model.get_layer('flatten').output)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Oc3xe8p-aYD",
        "outputId": "423450c0-0078-47ba-c242-a1f14ab18c0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "feature_extractor.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "=================================================================\n",
            "Total params: 18,816\n",
            "Trainable params: 18,816\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTXNZh5n-d5c"
      },
      "source": [
        "features = feature_extractor.predict(x_sample)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpJgM3O3_Uf3",
        "outputId": "c094e7fb-f53a-4e81-fb3b-92cda0cf863c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "features.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1600)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFxb89wk_WBo"
      },
      "source": [
        "label_a = []\n",
        "label_b = []\n",
        "correlation = []\n",
        "p_value = []"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdPPlibCAYUd"
      },
      "source": [
        "# counter = 0\n",
        "for i in range(size):\n",
        "    for j in range(i, size):\n",
        "        # counter += 1\n",
        "        label_a.append(y_sample[i])\n",
        "        label_b.append(y_sample[j])\n",
        "        rho = stats.pearsonr(features[i], features[j])\n",
        "        correlation.append(rho[0])\n",
        "        p_value.append(rho[1])\n",
        "# print(counter)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGjU22wkBtm5"
      },
      "source": [
        "data = {\n",
        "    'label_a':      label_a,\n",
        "    'label_b':      label_b,\n",
        "    'correlation':  correlation,\n",
        "    'p_value':      p_value\n",
        "}"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toxf-CV4CpSy"
      },
      "source": [
        "df = pd.DataFrame.from_dict(data)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ_3uQB4JPKv",
        "outputId": "16aca745-99ec-491f-c34f-fce97c6a6462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label_a</th>\n",
              "      <th>label_b</th>\n",
              "      <th>correlation</th>\n",
              "      <th>p_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.032373</td>\n",
              "      <td>1.955789e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.009075</td>\n",
              "      <td>7.168116e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>0.049564</td>\n",
              "      <td>4.745343e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.002620</td>\n",
              "      <td>9.166028e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.007761</td>\n",
              "      <td>7.563991e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.041182</td>\n",
              "      <td>9.961827e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.066764</td>\n",
              "      <td>7.551972e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0.175117</td>\n",
              "      <td>1.741163e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.086964</td>\n",
              "      <td>4.968844e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.030422</td>\n",
              "      <td>2.239077e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0.175277</td>\n",
              "      <td>1.661174e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.564167</td>\n",
              "      <td>3.953990e-135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.024372</td>\n",
              "      <td>3.299224e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.023964</td>\n",
              "      <td>3.380829e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.096970</td>\n",
              "      <td>1.023613e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0.087800</td>\n",
              "      <td>4.379988e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.111645</td>\n",
              "      <td>7.595037e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>-0.081193</td>\n",
              "      <td>1.151813e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.142563</td>\n",
              "      <td>1.020114e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.854782</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.895108</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.056944</td>\n",
              "      <td>2.273659e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0.074457</td>\n",
              "      <td>2.881504e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.033576</td>\n",
              "      <td>1.794714e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>0.040407</td>\n",
              "      <td>1.061605e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.099515</td>\n",
              "      <td>6.680601e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.099358</td>\n",
              "      <td>6.860261e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.071869</td>\n",
              "      <td>4.024743e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>0.200616</td>\n",
              "      <td>5.456682e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>0.200699</td>\n",
              "      <td>5.306639e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.144944</td>\n",
              "      <td>5.745111e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.168282</td>\n",
              "      <td>1.249459e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.095571</td>\n",
              "      <td>1.288710e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0.133031</td>\n",
              "      <td>9.252062e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.173000</td>\n",
              "      <td>3.233183e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.760266</td>\n",
              "      <td>1.095609e-301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.049599</td>\n",
              "      <td>4.729841e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0.124122</td>\n",
              "      <td>6.349325e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.049245</td>\n",
              "      <td>4.889938e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.038484</td>\n",
              "      <td>1.238662e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0.035285</td>\n",
              "      <td>1.583184e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.010296</td>\n",
              "      <td>6.806868e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0.221849</td>\n",
              "      <td>2.728469e-19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.015636</td>\n",
              "      <td>5.319663e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>0.295263</td>\n",
              "      <td>1.495291e-33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    label_a  label_b  correlation        p_value\n",
              "0         1        1     1.000000   0.000000e+00\n",
              "1         1        2     0.032373   1.955789e-01\n",
              "2         1        1    -0.009075   7.168116e-01\n",
              "3         1        9     0.049564   4.745343e-02\n",
              "4         1        2    -0.002620   9.166028e-01\n",
              "5         1        1     0.007761   7.563991e-01\n",
              "6         1        1    -0.041182   9.961827e-02\n",
              "7         1        0    -0.066764   7.551972e-03\n",
              "8         1        7     0.175117   1.741163e-12\n",
              "9         1        4     0.086964   4.968844e-04\n",
              "10        2        2     1.000000   0.000000e+00\n",
              "11        2        1     0.030422   2.239077e-01\n",
              "12        2        9     0.175277   1.661174e-12\n",
              "13        2        2     0.564167  3.953990e-135\n",
              "14        2        1     0.024372   3.299224e-01\n",
              "15        2        1     0.023964   3.380829e-01\n",
              "16        2        0     0.096970   1.023613e-04\n",
              "17        2        7     0.087800   4.379988e-04\n",
              "18        2        4     0.111645   7.595037e-06\n",
              "19        1        1     1.000000   0.000000e+00\n",
              "20        1        9    -0.081193   1.151813e-03\n",
              "21        1        2     0.142563   1.020114e-08\n",
              "22        1        1     0.854782   0.000000e+00\n",
              "23        1        1     0.895108   0.000000e+00\n",
              "24        1        0    -0.056944   2.273659e-02\n",
              "25        1        7     0.074457   2.881504e-03\n",
              "26        1        4     0.033576   1.794714e-01\n",
              "27        9        9     1.000000   0.000000e+00\n",
              "28        9        2     0.040407   1.061605e-01\n",
              "29        9        1    -0.099515   6.680601e-05\n",
              "30        9        1    -0.099358   6.860261e-05\n",
              "31        9        0     0.071869   4.024743e-03\n",
              "32        9        7     0.200616   5.456682e-16\n",
              "33        9        4     0.200699   5.306639e-16\n",
              "34        2        2     1.000000   0.000000e+00\n",
              "35        2        1     0.144944   5.745111e-09\n",
              "36        2        1     0.168282   1.249459e-11\n",
              "37        2        0     0.095571   1.288710e-04\n",
              "38        2        7     0.133031   9.252062e-08\n",
              "39        2        4     0.173000   3.233183e-12\n",
              "40        1        1     1.000000   0.000000e+00\n",
              "41        1        1     0.760266  1.095609e-301\n",
              "42        1        0    -0.049599   4.729841e-02\n",
              "43        1        7     0.124122   6.349325e-07\n",
              "44        1        4     0.049245   4.889938e-02\n",
              "45        1        1     1.000000   0.000000e+00\n",
              "46        1        0    -0.038484   1.238662e-01\n",
              "47        1        7     0.035285   1.583184e-01\n",
              "48        1        4     0.010296   6.806868e-01\n",
              "49        0        0     1.000000   0.000000e+00\n",
              "50        0        7     0.221849   2.728469e-19\n",
              "51        0        4     0.015636   5.319663e-01\n",
              "52        7        7     1.000000   0.000000e+00\n",
              "53        7        4     0.295263   1.495291e-33\n",
              "54        4        4     1.000000   0.000000e+00"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1lMduV0C02P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}